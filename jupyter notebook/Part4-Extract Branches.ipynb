{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import dijkstra\n",
    "import laspy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_pcd(path):\n",
    "    # Read the LAS file\n",
    "    inFile = laspy.read(path)\n",
    "    x,y,z = inFile.x, inFile.y, inFile.z\n",
    "    # Remove offset.\n",
    "    x_offset = x - np.min(x)\n",
    "    y_offset = y - np.min(y)\n",
    "    z_offset = z - np.min(z)\n",
    "    points = zip(x_offset,y_offset,z_offset)\n",
    "    # Write to pcd.\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    offset = [[np.min(x),np.min(y),np.min(z)]]\n",
    "    return pcd,offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_point_distances(pcd):\n",
    "    points = np.asarray(pcd.points)\n",
    "    unique_points = np.unique(points, axis=0)\n",
    "    pcd_unique = o3d.geometry.PointCloud()\n",
    "    pcd_unique.points = o3d.utility.Vector3dVector(unique_points)\n",
    "     # Calculate nearest neighbor distances after deduplication\n",
    "    nndist = np.array(pcd_unique.compute_nearest_neighbor_distance())\n",
    "    # Get distance statistics\n",
    "    min_distance = np.min(nndist)\n",
    "    max_distance = np.max(nndist)\n",
    "    mean_distance = np.mean(nndist)\n",
    "    return min_distance, max_distance, mean_distance\n",
    "\n",
    "def get_diameter_points(segment_pcd):\n",
    "    points = np.asarray(segment_pcd.points)\n",
    "    # Get coordinates in XY plane\n",
    "    points_2d = points[:, :2]\n",
    "    # Calculate distance matrix between point pairs\n",
    "    distances = scipy.spatial.distance.cdist(points_2d, points_2d)\n",
    "    # Get diameter\n",
    "    diameter = np.max(distances)\n",
    "    return diameter\n",
    "\n",
    "def get_diameter(pcd):\n",
    "    min_distance, max_distance, mean_distance = analyze_point_distances(pcd)\n",
    "    points = np.asarray(pcd.points)\n",
    "    min_pts = np.amin(points, axis=0)\n",
    "    # Calculate the number of vertical segments\n",
    "    # Vertical slicing of the point cloud\n",
    "    segment_points = points[\n",
    "            np.where((points[:, 2] >= min_pts[2]) & (points[:, 2] <  max_distance + min_pts[2]))]\n",
    "    segment_pcd = o3d.geometry.PointCloud()\n",
    "    segment_pcd.points = o3d.utility.Vector3dVector(segment_points)\n",
    "        # If there is only one cluster, it is considered the trunk part\n",
    "    diameter = get_diameter_points(segment_pcd)\n",
    "    return diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de965142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance Clustering Algorithm\n",
    "def cluster_points(pcd, radius, min_cluster_size=1, max_cluster_size=10000):\n",
    "    # kd tree\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    points_length = len(pcd.points)\n",
    "    # Initializes a list of the same size as the point cloud, recording whether each point has been visited\n",
    "    visited = [-1] * points_length\n",
    "    clusters = []\n",
    "    for index in range(points_length):\n",
    "        # If the point has already been visited, skip it\n",
    "        if visited[index] == 1:\n",
    "            continue\n",
    "        active_points = []\n",
    "        active_index = 0\n",
    "        # Mark the current point as visited and add it to the active point list\n",
    "        active_points.append(index)\n",
    "        visited[index] = 1\n",
    "        while active_index < len(active_points):\n",
    "            [k, indices, _] = kdtree.search_radius_vector_3d(pcd.points[active_points[active_index]],radius)\n",
    "            if k == 1:\n",
    "                active_index += 1\n",
    "                continue\n",
    "            for i in range(k):\n",
    "                if indices[i] == points_length or visited[indices[i]] == 1:\n",
    "                    continue\n",
    "                active_points.append(indices[i])\n",
    "                visited[indices[i]] = 1\n",
    "            active_index += 1\n",
    "        # If the cluster size is within the specified range, the cluster is logged\n",
    "        if max_cluster_size > len(active_points) >= min_cluster_size:\n",
    "            clusters.append(active_points)\n",
    "    return clusters\n",
    "\n",
    "def concatenate_points(points):\n",
    "    # Concatenates multiple arrays of points into a single array\n",
    "    for k in range(len(points)):\n",
    "        if k ==0:\n",
    "            points_concatenate = points[0]\n",
    "        else:\n",
    "            points_concatenate  = np.concatenate((points[k],points_concatenate),axis=0)\n",
    "    return points_concatenate\n",
    "\n",
    "def cultivate_length(points):\n",
    "    # Calculate the total distance between points\n",
    "    points_dist = []\n",
    "    for i in range(len(points)):\n",
    "        if i != 0:\n",
    "            dist = np.linalg.norm(np.array(points[i]) - np.array(points[i - 1]))\n",
    "            points_dist.append(dist)\n",
    "    dist_sum = np.sum(points_dist)\n",
    "    return dist_sum\n",
    "\n",
    "def make_graph(pcd, radius):\n",
    "    # Construct a 3D graph using graph theory\n",
    "    graph = dijkstra.Graph()\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    target_points = np.asarray(pcd.points)\n",
    "    for i in range(len(target_points)):\n",
    "        # Use a radius-based method to construct connections between points\n",
    "        [k, idx, d] = pcd_tree.search_radius_vector_3d(target_points[i], radius)\n",
    "        for j in range(k):\n",
    "            graph.add_edge(str(target_points[i]), str(target_points[idx[j]]), d[j])\n",
    "    return graph\n",
    "\n",
    "def get_path_points(start_point, end_point, graph):\n",
    "    dijkstra_graph = dijkstra.DijkstraSPF(graph, str(start_point))\n",
    "    # Retrieve the shortest path from the start point to the end point\n",
    "    get_point = dijkstra_graph.get_path(str(end_point))\n",
    "    dijkstra_path = []\n",
    "    # Iterate through each point in the path\n",
    "    for i in range(len(get_point)):\n",
    "        remove_str = get_point[i].strip('[]').split()\n",
    "        # Convert a list of strings to a list of floating-point numbers\n",
    "        numb = list(map(float, remove_str))\n",
    "        dijkstra_path.append(numb)\n",
    "    return dijkstra_path\n",
    "\n",
    "def find_nearest_point(branch_points, all_points, graph):\n",
    "    # Initialize a list to store the distance from each branch point to its nearest point\n",
    "    points_dist = []\n",
    "    pcd_trunk = o3d.geometry.PointCloud()\n",
    "    pcd_trunk.points = o3d.utility.Vector3dVector(np.asarray(all_points))\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_trunk)\n",
    "    # Iterate over each branch point to find its nearest point in the point cloud\n",
    "    for i in range(len(branch_points)):\n",
    "        [k, idx, d] = pcd_tree.search_knn_vector_3d(branch_points[i], 1)\n",
    "        dist = np.linalg.norm(np.asarray(branch_points[i]) - np.asarray(pcd_trunk.points)[idx][0])\n",
    "        points_dist.append(dist)\n",
    "    # Find the index of the smallest distance and return the corresponding branch point\n",
    "    index = np.where(points_dist == np.amin(points_dist))[0]\n",
    "    branch_point = branch_points[index[0]]\n",
    "    return branch_point\n",
    "\n",
    "def remove_points_not_need(points_all, points_not_need):\n",
    "    # Initialize a list to store the points that need to be kept\n",
    "    points_need = []\n",
    "    for i in range(len(points_all)):\n",
    "        if (np.round(points_all[i], 4) == np.round(points_not_need, 4)).all(1).any():\n",
    "            pass\n",
    "        else:\n",
    "            points_need.append(points_all[i])\n",
    "    # Return the list of needed points\n",
    "    return points_need\n",
    "\n",
    "def remove_affect_points(array_affect):\n",
    "    mask = np.ones(len(array_affect), dtype=bool)\n",
    "    # Iterate through all paths, checking if each path is a subset of any other path\n",
    "    for i, arr in enumerate(array_affect):\n",
    "        other_arrays = np.delete(array_affect, i, axis=0)\n",
    "        for other in other_arrays:\n",
    "            if np.all(np.isin(arr, other)):\n",
    "                mask[i] = False\n",
    "                break\n",
    "    filtered_array = array_affect[mask]\n",
    "    return filtered_array\n",
    "\n",
    "def find_outside_points(pcd,input_radius,trunk_diameter):\n",
    "    points = np.asarray(pcd.points)\n",
    "    min_distance, max_distance, mean_distance = analyze_point_distances(pcd)\n",
    "    tree = cKDTree(points)\n",
    "    points_get = []\n",
    "    # Iterate through the set of points to find the outermost edge points\n",
    "    for i in range(len(points)):\n",
    "        index = tree.query_ball_point(points[i],0.02)\n",
    "        point_need1 = points[np.where(points[index][:,2]>points[i][2])]\n",
    "        point_need2 = points[np.where(points[index][:,2]<points[i][2])]\n",
    "        if len(point_need1)==0 or len(point_need2)==0:\n",
    "            points_get.append(points[i])\n",
    "    z_points = sorted(points, key=(lambda z: z[2]))\n",
    "    min_pts = z_points[0]\n",
    "    if input_radius == None:\n",
    "        results = False\n",
    "        k = 0\n",
    "        while not results:\n",
    "            array_affect = []\n",
    "            current_radius = (2*(k+1)) * trunk_diameter\n",
    "            print(\"current_radius\",current_radius)\n",
    "            try:\n",
    "                graph = make_graph(pcd,current_radius)\n",
    "                # For each edge point, find the path to the lowest point\n",
    "                for i in range(len(points_get)):\n",
    "                    path = get_path_points(points_get[i],min_pts,graph)\n",
    "                    array_affect.append(path)\n",
    "                results = True\n",
    "            except KeyError:\n",
    "                print(\"failed\",current_radius)\n",
    "                k += 1\n",
    "        # Use a shortest path algorithm to remove incorrectly identified edge points\n",
    "        iltered_array = remove_affect_points(np.asarray(array_affect))\n",
    "        out = []\n",
    "        for i in range(len(iltered_array)):\n",
    "            out.append(iltered_array[i][0])\n",
    "        return out,graph,current_radius\n",
    "    else:\n",
    "        array_affect = []\n",
    "        graph = make_graph(pcd,input_radius)\n",
    "        for i in range(len(points_get)):\n",
    "            path = get_path_points(points_get[i],min_pts,graph)\n",
    "            array_affect.append(path)\n",
    "        iltered_array = remove_affect_points(np.asarray(array_affect))\n",
    "        out = []\n",
    "        for i in range(len(iltered_array)):\n",
    "            out.append(iltered_array[i][0])\n",
    "        return out,graph,None\n",
    "\n",
    "def clusters_to_pcd(pcd, dist, num):\n",
    "    # Cluster the point cloud using the Euclidean distance clustering algorithm\n",
    "    clusters = cluster_points(pcd, dist, min_cluster_size=num, max_cluster_size=100000)\n",
    "    points = np.asarray(pcd.points)\n",
    "    point_list = []\n",
    "    # Iterate through each cluster, retrieve the points within, and add them to the list\n",
    "    for i in clusters:\n",
    "        point = points[i]\n",
    "        point_list.append(point)\n",
    "    concatenated_clusters = concatenate_points(point_list)\n",
    "    pcd_trans = o3d.geometry.PointCloud()\n",
    "    pcd_trans.points = o3d.utility.Vector3dVector(np.asarray(concatenated_clusters))\n",
    "    return pcd_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eca69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_support_structure_graph(pcd,trunk_diameter):\n",
    "    pcd_trans = clusters_to_pcd(pcd, 0.5, 5)\n",
    "    graph = make_graph(pcd_trans, 0.5)\n",
    "    outside_points,graph,current_radius = find_outside_points(pcd_trans, None,trunk_diameter)\n",
    "    z_points = sorted(np.asarray(pcd_trans.points), key=(lambda z: z[2]))\n",
    "    min_pts = z_points[0]\n",
    "    points = []\n",
    "    # Get the shortest paths from the lowest point to all outermost points\n",
    "    for i in range(len(outside_points)):\n",
    "        path = get_path_points(min_pts, np.asarray(outside_points)[i], graph)\n",
    "        points.append(path)\n",
    "    concatenated_path = concatenate_points(points)\n",
    "    concatenated_path_unique = np.unique(concatenated_path, axis=0)\n",
    "    # Save the point cloud after removing the support structures\n",
    "    pcd_remove = o3d.geometry.PointCloud()\n",
    "    pcd_remove.points = o3d.utility.Vector3dVector(np.asarray(concatenated_path_unique))\n",
    "    return pcd_remove, pcd_trans,current_radius\n",
    "\n",
    "def remove_support_structure_intensity(las_path,lidar_skeleton,lidar_pcd,intensity_threshold,trunk_radius):\n",
    "    las = laspy.read(las_path)\n",
    "    intensity = las.intensity\n",
    "    # Calculate the average intensity value of the entire point cloud\n",
    "    intensity_mean_all = np.mean(intensity)\n",
    "    points = np.asarray(lidar_skeleton.points)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(lidar_pcd)\n",
    "    support_structure_points = []\n",
    "    points_intensity_value = []\n",
    "    # Compare the intensity value of each point with the average intensity of the entire point cloud\n",
    "    for i in range(len(points)):\n",
    "        [k, idx, d] = pcd_tree.search_radius_vector_3d(lidar_skeleton.points[i],trunk_radius)\n",
    "        points_intensity = intensity[idx]\n",
    "        intensity_mean = np.mean(points_intensity)\n",
    "        points_intensity_value.append(intensity_mean)\n",
    "        if intensity_mean>intensity_mean_all * intensity_threshold:#recommend:1.1-1.3\n",
    "            support_structure_points.append(points[i])\n",
    "    if len(support_structure_points) > 0:\n",
    "        pcd_intensity = o3d.geometry.PointCloud()\n",
    "        pcd_intensity.points = o3d.utility.Vector3dVector(np.asarray(support_structure_points))\n",
    "        pcd_intensity.paint_uniform_color([1, 0.0, 0.0])\n",
    "        return pcd_intensity,points_intensity_value\n",
    "    elif len(support_structure_points) == 0:\n",
    "        return None\n",
    "\n",
    "def intensity_value_normalization(points_intensity_value, lidar_skeleton_pcd):\n",
    "    cool_cmap = plt.get_cmap('cividis')\n",
    "    min_intensity = np.min(points_intensity_value)\n",
    "    max_intensity = np.max(points_intensity_value)\n",
    "    # Create a color array based on normalized intensity values\n",
    "    colors = cool_cmap((points_intensity_value - min_intensity) / (max_intensity - min_intensity))\n",
    "    # Set the point cloud colors\n",
    "    cloud = o3d.geometry.PointCloud()\n",
    "    cloud.points = o3d.utility.Vector3dVector(np.asarray(lidar_skeleton_pcd.points))\n",
    "    cloud.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    # Visualize the point cloud using Open3D\n",
    "    o3d.visualization.draw_geometries([cloud], window_name=\"visualization_points\",\n",
    "                                      width=800, height=800, left=50, top=50,\n",
    "                                      mesh_show_back_face=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_two_main_branches(pcd, current_radius, trunk_diameter):\n",
    "    outside_points,graph,_ = find_outside_points(pcd,current_radius,trunk_diameter)\n",
    "    z_points = sorted(np.asarray(pcd.points), key=(lambda z: z[2]))\n",
    "    min_pts, max_pts = z_points[0], z_points[-1]\n",
    "    max_path = get_path_points(min_pts, max_pts, graph)\n",
    "    points = []\n",
    "    for i in range(len(outside_points)):\n",
    "        get_path = get_path_points(min_pts, np.asarray(outside_points)[i], graph)\n",
    "        need_points = remove_points_not_need(get_path, max_path)\n",
    "        points.append(need_points)\n",
    "    get_points = []\n",
    "    end_points = []\n",
    "    start_points = []\n",
    "    list_node_point = []\n",
    "    for i in range(len(points)):\n",
    "        if len(points[i]) > 0:\n",
    "            end_points.append(points[i][-1])\n",
    "            start_points.append(points[i][0])\n",
    "            get_points.append(points[i])\n",
    "    # Obtain the point clouds for the branch groups\n",
    "    min_pts1 = np.amin(start_points, axis=0)[2]\n",
    "    min_pts2 = np.asarray(start_points)[np.where(np.asarray(start_points)[:, 2] > min_pts1)]\n",
    "    z_points = sorted(min_pts2, key=(lambda z: z[2]))[0]\n",
    "    index1 = np.where(np.asarray(start_points)[:, 2] == min_pts1)\n",
    "    index2 = np.where(np.asarray(start_points)[:, 2] == z_points[2])\n",
    "    points_length = []\n",
    "    for i in range(len(index2[0])):\n",
    "        length = cultivate_length(get_points[index2[0][i]])\n",
    "        points_length.append(length)\n",
    "    path = np.asarray(get_points,dtype=object)[index2[0][np.where(points_length == np.max(points_length))[0]]]\n",
    "    points_length1 = []\n",
    "    for i in range(len(index1[0])):\n",
    "        length1 = cultivate_length(get_points[index1[0][i]])\n",
    "        points_length1.append(length1)\n",
    "    path1 = np.asarray(get_points,dtype=object)[index1[0][np.where(points_length1 == np.max(points_length1))[0]]]\n",
    "    trunk_branches_point = np.concatenate((max_path, path[0], path1[0]), axis=0)\n",
    "    trunk_branches_list = [max_path, path[0], path1[0]]\n",
    "    branch_point = find_nearest_point(max_path,path[0],graph)\n",
    "    branch_point1 = find_nearest_point(max_path,path1[0],graph)\n",
    "    list_node_point.append(branch_point)\n",
    "    list_node_point.append(branch_point1)\n",
    "    return trunk_branches_point, outside_points, max_path, trunk_branches_list, list_node_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_intensity_and_graph(pcd_remove, pcd_all, trunk_diameter, current_radius):\n",
    "    if pcd_all != None:\n",
    "        trunk_branches_point, _, max_path, _, _ = extract_two_main_branches(pcd_remove,current_radius,trunk_diameter,log_func=log_func)\n",
    "        # Get the branches misidentified as support structures\n",
    "        points_need = remove_points_not_need(pcd_all.points, trunk_branches_point)\n",
    "        if len(points_need) > 0:\n",
    "            points_list = []\n",
    "            pcd_need = o3d.geometry.PointCloud()\n",
    "            pcd_need.points = o3d.utility.Vector3dVector(np.asarray(points_need))\n",
    "            # Use Euclidean distance clustering\n",
    "            ec = cluster_points(pcd_need, radius=0.1)\n",
    "            for i in range(len(ec)):\n",
    "                ind = ec[i]\n",
    "                clusters_cloud = pcd_need.select_by_index(ind)\n",
    "                if len(clusters_cloud.points) > 20:\n",
    "                    points_list.append(np.asarray(clusters_cloud.points))\n",
    "            if len(points_list) > 0:\n",
    "                concatenated = concatenate_points(points_list)\n",
    "                points = remove_points_not_need(np.asarray(pcd_remove.points), concatenated)\n",
    "                pcd_finall = o3d.geometry.PointCloud()\n",
    "                pcd_finall.points = o3d.utility.Vector3dVector(np.asarray(points))\n",
    "            elif len(points_list) == 0:\n",
    "                pcd_finall = pcd_remove\n",
    "        elif len(points_need) == 0:\n",
    "            pcd_finall = pcd_remove\n",
    "    else:\n",
    "        pcd_finall = pcd_remove\n",
    "    return pcd_finall, max_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ac1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_skeleton(start_point, end_point, current_point, iterations):\n",
    "    # Smooth step size\n",
    "    step_size = 0.1\n",
    "    for i in range(iterations):\n",
    "        direction_adjustment = (start_point - current_point) / 2 + (end_point - current_point) / 2\n",
    "        # Adjust the position of the current point\n",
    "        current_point = current_point + step_size * direction_adjustment\n",
    "    return current_point\n",
    "\n",
    "def repair_local(pcd_start,pcd1,max_path,radius, current_radius,trunk_height):\n",
    "    # Voxel downsampling\n",
    "    pcd_down_sample = pcd1.voxel_down_sample(voxel_size = 0.03)\n",
    "    pcd = clusters_to_pcd(pcd_start,radius,4)\n",
    "    clusters = cluster_points(pcd,radius,min_cluster_size=4, max_cluster_size=100000)\n",
    "     # Get each broken branch\n",
    "    length = []\n",
    "    for i in range(len(clusters)):\n",
    "        length.append(len(clusters[i]))\n",
    "    max_length = np.where(length==np.max(length))[0]\n",
    "    clusters.remove(clusters[max_length[0]])\n",
    "    pcd_max = o3d.geometry.PointCloud()\n",
    "    pcd_max.points = o3d.utility.Vector3dVector(np.asarray(max_path))\n",
    "    pcd_tree_max = o3d.geometry.KDTreeFlann(pcd_max)\n",
    "    z_points = sorted(np.asarray(pcd_down_sample.points), key=(lambda z: z[2]))\n",
    "    min_pts = sorted(z_points, key=(lambda z: z[2]))[0]\n",
    "    nearest_points_list = []\n",
    "    point_list = []\n",
    "    # The nearest point to the most populous skeleton is the fracture point for each branch\n",
    "    for i in range(len(clusters)):\n",
    "        distance = []\n",
    "        point = np.asarray(pcd.points)[clusters[i]]\n",
    "        for j in range(len(point)):\n",
    "            [k, idx, d] = pcd_tree_max.search_knn_vector_3d(point[j],1)\n",
    "            distance.append(np.sqrt(d)[0])\n",
    "        get_point = point[np.where(distance == np.amin(distance))][0]\n",
    "        tree = cKDTree(point)\n",
    "        point_index = tree.query_ball_point(get_point,0.02)\n",
    "        point_need1 = point[np.where(point[point_index][:,2]>get_point[2])]\n",
    "        point_need2 = point[np.where(point[point_index][:,2]<get_point[2])]\n",
    "        if len(point_need1)==0 or len(point_need2)==0 :\n",
    "            nearest_points_list.append(get_point)\n",
    "            point_list.append(point)\n",
    "    if len(nearest_points_list) > 0 :\n",
    "        pcd_min_point = o3d.geometry.PointCloud()\n",
    "        pcd_min_point.points = o3d.utility.Vector3dVector(np.asarray(nearest_points_list))\n",
    "        # Select points from the downsampled point cloud for repair\n",
    "        pcd_all = pcd_min_point + pcd_down_sample\n",
    "        graph = make_graph(pcd_all,current_radius)\n",
    "        points_path_all = []\n",
    "        for i in range(len(nearest_points_list)):\n",
    "            path = get_path_points(np.asarray(nearest_points_list)[i],min_pts,graph)\n",
    "            point_middle = np.mean(point_list[i],axis=0)\n",
    "            middle_dist = np.linalg.norm(np.array(point_middle)-np.array(path[1]))\n",
    "            middle_dist1 = np.linalg.norm(np.array(point_middle)-np.array(path[2]))\n",
    "            if middle_dist1 > middle_dist:\n",
    "                points_remain = remove_points_not_need(np.asarray(pcd.points),np.asarray(point_list[i]))\n",
    "                pcd_remove_points = o3d.geometry.PointCloud()\n",
    "                pcd_remove_points.points = o3d.utility.Vector3dVector(np.asarray(points_remain))\n",
    "                pcd_tree_remove = o3d.geometry.KDTreeFlann(pcd_remove_points)\n",
    "                points_path = []\n",
    "                for l in range(len(path)):\n",
    "                    [k, idx, d] = pcd_tree_remove.search_knn_vector_3d(path[l],1)\n",
    "                    nearest_point =  np.asarray(pcd_remove_points.points)[idx][0]\n",
    "                    [k1, idx1, d1] = pcd_tree_max.search_knn_vector_3d(path[l],1)\n",
    "                    [k2, idx2, d2] = pcd_tree_max.search_knn_vector_3d(nearest_point,1)\n",
    "                    nearest_dist = np.sqrt(d1) - np.sqrt(d2)\n",
    "                    if (np.sqrt(d) > 0.05)  &(path[l][2]>trunk_height):\n",
    "                        points_path.append(path[l])\n",
    "                    elif (np.sqrt(d) < 0.05) & (path[l][2] > nearest_point[2]) & (nearest_dist > 0) :\n",
    "                        points_path.append(path[l])\n",
    "                    else:\n",
    "                        break\n",
    "                if len(points_path)>0:\n",
    "                    points_path_all.append(points_path)\n",
    "            else:\n",
    "                continue\n",
    "        if len(points_path_all)>0:\n",
    "            # Smooth the selected point cloud\n",
    "            points_smooth = []\n",
    "            for i in range(len(points_path_all)):\n",
    "                points_smooth1 = []\n",
    "                for j in range(len(points_path_all[i])):\n",
    "                    if len(points_path_all[i]) > 2:\n",
    "                            if j ==1:\n",
    "                                p = smooth_skeleton(np.array(points_path_all[i][j-1]),np.array(points_path_all[i][j+1]),np.array(points_path_all[i][j]),10)\n",
    "                                points_smooth.append(p)\n",
    "                                points_smooth1.append(p)\n",
    "                            elif j == len(points_path_all[i])-1:\n",
    "                                break\n",
    "                            elif j > 1:\n",
    "                                p = smooth_skeleton(np.array(points_path_all[i][j-1]),np.array(points_path_all[i][j+1]),p,10)\n",
    "                                points_smooth.append(p)\n",
    "            if len(points_smooth)>0:\n",
    "                pcd_smooth = o3d.geometry.PointCloud()\n",
    "                pcd_smooth.points = o3d.utility.Vector3dVector(np.asarray(points_smooth))\n",
    "                #Add the smoothed point cloud to the skeleton point cloud\n",
    "                pcd_whole = pcd_smooth + pcd\n",
    "            else:\n",
    "                pcd_whole = pcd\n",
    "        else:\n",
    "            pcd_whole = pcd\n",
    "    else:\n",
    "        pcd_whole = pcd\n",
    "    return pcd_whole\n",
    "\n",
    "def repair_tree_dijkstra(pcd_whole,trunk_diameter):\n",
    "    points_all = []\n",
    "    z_points = sorted(np.asarray(pcd_whole.points), key=(lambda z: z[2]))\n",
    "    min_pts = z_points[0]\n",
    "    outside_points, graph, current_radius = find_outside_points(pcd_whole, None, trunk_diameter)\n",
    "    pcd_whole2 = o3d.geometry.PointCloud()\n",
    "    pcd_whole2.points = o3d.utility.Vector3dVector(np.asarray(outside_points))\n",
    "    # Use linear interpolation to complete\n",
    "    min_distance, max_distance, mean_distance = analyze_point_distances(pcd_whole)\n",
    "    step = mean_distance\n",
    "    for i in range(len(np.asarray(outside_points))):\n",
    "        points_insert = [] \n",
    "        path = get_path_points(np.asarray(min_pts), np.asarray(outside_points)[i], graph)\n",
    "        for j in range(len(path)):\n",
    "            if j != 0:\n",
    "                dist = np.linalg.norm(np.array(path[j]) - np.array(path[j - 1]))\n",
    "                # If the distance is greater than mean_distance, then perform interpolation\n",
    "                if dist >= mean_distance:\n",
    "                    number = max(1, int(np.ceil(dist / step)))  \n",
    "                    for k in range(1, number):  \n",
    "                         # Use parametric interpolation to ensure uniform distribution\n",
    "                        t = k / number\n",
    "                        point_need = np.asarray(path[j - 1]) * (1 - t) + np.asarray(path[j]) * t\n",
    "                        points_insert.append(point_need)\n",
    "        # Add original path points and interpolated points\n",
    "        if len(points_insert) > 0:\n",
    "            points_all.append(points_insert)\n",
    "        if len(path) > 0:\n",
    "            points_all.append(path)\n",
    "    concatenated = concatenate_points(points_all)\n",
    "    points_concatenate_remove = np.unique(concatenated, axis=0)\n",
    "    # Obtain the completed point cloud\n",
    "    pcd_finall_repair = o3d.geometry.PointCloud()\n",
    "    pcd_finall_repair.points = o3d.utility.Vector3dVector(np.asarray(points_concatenate_remove))\n",
    "    pcd_finall_repair.paint_uniform_color([1, 0.0, 0.0])\n",
    "    return pcd_finall_repair, mean_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_branch(pcd, mean_distance, current_radius, trunk_diameter):\n",
    "    branch_path_points = []\n",
    "    pcd_all = o3d.geometry.PointCloud()\n",
    "    pcd_all.points = o3d.utility.Vector3dVector(np.asarray(pcd.points))\n",
    "    trunk_points,outside_need,_,trunk_branches_path,branch_nodes = extract_two_main_branches(pcd,None, trunk_diameter)\n",
    "    points_need = remove_points_not_need(np.asarray(pcd_all.points),trunk_points)\n",
    "    pcd_remove_trunk = o3d.geometry.PointCloud()\n",
    "    pcd_remove_trunk.points = o3d.utility.Vector3dVector(np.asarray(points_need))\n",
    "    pcd_trunk = o3d.geometry.PointCloud()\n",
    "    pcd_trunk.points = o3d.utility.Vector3dVector(np.asarray(trunk_points))\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_trunk)\n",
    "    graph = make_graph(pcd_remove_trunk,current_radius)\n",
    "    # Cluster the remaining parts of the pear tree point cloud\n",
    "    clusters = cluster_points(pcd_remove_trunk,mean_distance)\n",
    "    for j in range(len(clusters)):\n",
    "        points_distance = []\n",
    "        points_path = []\n",
    "        outside_point = []\n",
    "        clusters_cloud = pcd_remove_trunk.select_by_index(clusters[j])\n",
    "        if len(clusters_cloud.points)>1:\n",
    "            points_trunk = np.asarray(clusters_cloud.points)\n",
    "            for k in range(len(points_trunk)):\n",
    "                if (np.round(points_trunk[k],4) == np.round(outside_need,4)).all(1).any():\n",
    "                    outside_point.append(points_trunk[k])\n",
    "            # Only one outermost point as a first-level branch\n",
    "            if len(outside_point) == 1:\n",
    "                nearest_point = find_nearest_point(points_trunk,trunk_points,graph)\n",
    "                branch_path = get_path_points(nearest_point,outside_point[0],graph)\n",
    "                [_, idx, _] = pcd_tree.search_knn_vector_3d(nearest_point, 1)\n",
    "                node_point = np.asarray(trunk_points)[idx[0]]\n",
    "                if len(branch_path)>30:\n",
    "                    branch_path_points.append(branch_path)\n",
    "                    branch_nodes.append(node_point)\n",
    "            # The longest branch with multiple outermost points as a first-level branch\n",
    "            elif len(outside_point) > 1:\n",
    "                nearest_point1 = find_nearest_point(points_trunk,trunk_points,graph)\n",
    "                [_, idx1, _] = pcd_tree.search_knn_vector_3d(nearest_point1, 1)\n",
    "                node_point1 = np.asarray(trunk_points)[idx1[0]]\n",
    "                for i in range(len(outside_point)):\n",
    "                    path = get_path_points(np.asarray(nearest_point1),np.asarray(outside_point[i]),graph)\n",
    "                    points_path.append(path)\n",
    "                    dist = cultivate_length(path)\n",
    "                    points_distance.append(dist)\n",
    "                index = np.where(points_distance == np.amax(points_distance))[0]\n",
    "                path_max = points_path[index[0]]\n",
    "                if len(path_max)>30:\n",
    "                    branch_path_points.append(path_max)\n",
    "                    branch_nodes.append(node_point1)\n",
    "    branch_number = len(branch_path_points) + 3\n",
    "    tree_points = np.concatenate((branch_path_points, trunk_branches_path), axis=0)\n",
    "    return branch_nodes,branch_number,tree_points,outside_point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
