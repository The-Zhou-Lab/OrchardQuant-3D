{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9a1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import dijkstra\n",
    "import laspy\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9879e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance Clustering Algorithm\n",
    "def cluster_points(pcd, radius, min_cluster_size=1, max_cluster_size=10000):\n",
    "    # kd tree\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd)  \n",
    "    points_length = len(pcd.points)\n",
    "    # Initializes a list of the same size as the point cloud, recording whether each point has been visited\n",
    "    visited = [-1] * points_length\n",
    "    clusters = []\n",
    "    for index in range(points_length):\n",
    "        # If the point has already been visited, skip it\n",
    "        if visited[index] == 1:\n",
    "            continue\n",
    "        active_points = []\n",
    "        active_index = 0\n",
    "        # Mark the current point as visited and add it to the active point list\n",
    "        active_points.append(index)\n",
    "        visited[index] = 1\n",
    "        while active_index < len(active_points):\n",
    "            [k, indices, _] = kdtree.search_radius_vector_3d(pcd.points[active_points[active_index]],radius)\n",
    "            if k == 1: \n",
    "                active_index += 1\n",
    "                continue\n",
    "            for i in range(k):\n",
    "                if indices[i] == points_length or visited[indices[i]] == 1:\n",
    "                    continue  \n",
    "                active_points.append(indices[i])\n",
    "                visited[indices[i]] = 1\n",
    "            active_index += 1\n",
    "        # If the cluster size is within the specified range, the cluster is logged\n",
    "        if max_cluster_size > len(active_points) >= min_cluster_size:\n",
    "            clusters.append(active_points)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb5dabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outside_points(points, radius, graph):\n",
    "    tree = cKDTree(points)\n",
    "    points_get = []\n",
    "    # Iterate through the set of points to find the outermost edge points\n",
    "    for i in range(len(points)):\n",
    "        index = tree.query_ball_point(points[i], radius)\n",
    "        point_need1 = points[np.where(points[index][:, 2] > points[i][2])]\n",
    "        point_need2 = points[np.where(points[index][:, 2] < points[i][2])]\n",
    "        if len(point_need1) == 0 or len(point_need2) == 0:\n",
    "            points_get.append(points[i])\n",
    "    array_affect = []\n",
    "    z_points = sorted(points, key=(lambda z: z[2]))\n",
    "    min_pts = z_points[0]\n",
    "    # For each edge point, find the path to the lowest point\n",
    "    for i in range(len(points_get)):\n",
    "        path = get_path_points(points_get[i], min_pts, graph)\n",
    "        array_affect.append(path)\n",
    "    # Use a shortest path algorithm to remove incorrectly identified edge points\n",
    "    iltered_array = remove_affect_points(np.asarray(array_affect,dtype=object))\n",
    "    out = []\n",
    "    for i in range(len(iltered_array)):\n",
    "        out.append(iltered_array[i][0])\n",
    "    return out\n",
    "\n",
    "def clusters_to_pcd(pcd, dist, num):\n",
    "    # Cluster the point cloud using the Euclidean distance clustering algorithm\n",
    "    clusters = cluster_points(pcd, dist, min_cluster_size=num, max_cluster_size=100000)\n",
    "    points = np.asarray(pcd.points)\n",
    "    point_list = []\n",
    "    # Iterate through each cluster, retrieve the points within, and add them to the list\n",
    "    for i in clusters:\n",
    "        point = points[i]\n",
    "        point_list.append(point)\n",
    "    concatenated_clusters = concatenate_points(point_list)\n",
    "    pcd_trans = o3d.geometry.PointCloud()\n",
    "    pcd_trans.points = o3d.utility.Vector3dVector(np.asarray(concatenated_clusters))\n",
    "    return pcd_trans\n",
    "\n",
    "def remove_support_structure_graph(pcd):\n",
    "    pcd_trans = clusters_to_pcd(pcd, 0.5, 5)\n",
    "    graph = make_graph(pcd_trans, 0.5)\n",
    "    outside_points = find_outside_points(np.asarray(pcd_trans.points), 0.05, graph)\n",
    "    z_points = sorted(np.asarray(pcd_trans.points), key=(lambda z: z[2]))\n",
    "    min_pts = z_points[0]\n",
    "    points = []\n",
    "    # Get the shortest paths from the lowest point to all outermost points\n",
    "    for i in range(len(outside_points)):\n",
    "        path = get_path_points(min_pts, np.asarray(outside_points)[i], graph)\n",
    "        points.append(path)\n",
    "    concatenated_path = concatenate_points(points)\n",
    "    concatenated_path_unique = np.unique(concatenated_path, axis=0)\n",
    "    # Save the point cloud after removing the support structures\n",
    "    pcd_remove = o3d.geometry.PointCloud()\n",
    "    pcd_remove.points = o3d.utility.Vector3dVector(np.asarray(concatenated_path_unique))\n",
    "    return pcd_remove, pcd_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cbd13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_support_structure_intensity(las_path,lidar_skeleton,lidar_pcd):\n",
    "    las = laspy.read(las_path)\n",
    "    intensity = las.intensity\n",
    "    # Calculate the average intensity value of the entire point cloud\n",
    "    intensity_mean_all = np.mean(intensity)\n",
    "    points = np.asarray(lidar_skeleton.points)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(lidar_pcd)\n",
    "    support_structure_points = []\n",
    "    points_intensity_value = []\n",
    "    # Compare the intensity value of each point with the average intensity of the entire point cloud\n",
    "    for i in range(len(points)):\n",
    "        [k, idx, d] = pcd_tree.search_radius_vector_3d(lidar_skeleton.points[i],0.05)\n",
    "        points_intensity = intensity[idx]\n",
    "        intensity_mean = np.mean(points_intensity)\n",
    "        points_intensity_value.append(intensity_mean)\n",
    "        if intensity_mean>intensity_mean_all * 1.1:#recommend:1.1-1.3\n",
    "            support_structure_points.append(points[i])\n",
    "    if len(support_structure_points) > 0:\n",
    "        pcd_intensity = o3d.geometry.PointCloud()\n",
    "        pcd_intensity.points = o3d.utility.Vector3dVector(np.asarray(support_structure_points))\n",
    "        pcd_intensity.paint_uniform_color([1, 0.0, 0.0])\n",
    "        return pcd_intensity,points_intensity_value\n",
    "    elif len(support_structure_points) == 0:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5599b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_skeleton(start_point, end_point, current_point, iterations):\n",
    "    # Smooth step size\n",
    "    step_size = 0.1\n",
    "    for i in range(iterations):\n",
    "        direction_adjustment = (start_point - current_point) / 2 + (end_point - current_point) / 2\n",
    "        # Adjust the position of the current point\n",
    "        current_point = current_point + step_size * direction_adjustment\n",
    "    return current_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1bd8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_local(pcd_start,pcd1,max_path,radius,min_cluster):\n",
    "    # Voxel downsampling\n",
    "    pcd_down_sample = pcd1.voxel_down_sample(voxel_size = 0.03)\n",
    "    pcd = clusters_to_pcd(pcd_start,radius,min_cluster)\n",
    "    clusters = cluster_points(pcd,radius,min_cluster_size=min_cluster, max_cluster_size=100000)\n",
    "     # Get each broken branch\n",
    "    length = []\n",
    "    for i in range(len(clusters)):\n",
    "        length.append(len(clusters[i]))\n",
    "    max_length = np.where(length==np.max(length))[0]\n",
    "    clusters.remove(clusters[max_length[0]])\n",
    "    pcd_max = o3d.geometry.PointCloud()\n",
    "    pcd_max.points = o3d.utility.Vector3dVector(np.asarray(max_path))\n",
    "    pcd_tree_max = o3d.geometry.KDTreeFlann(pcd_max)\n",
    "    z_points = sorted(np.asarray(pcd_down_sample.points), key=(lambda z: z[2]))\n",
    "    min_pts = sorted(z_points, key=(lambda z: z[2]))[0]\n",
    "    nearest_points_list = []\n",
    "    point_list = []\n",
    "    # The nearest point to the most populous skeleton is the fracture point for each branch\n",
    "    for i in range(len(clusters)):\n",
    "        distance = []\n",
    "        point = np.asarray(pcd.points)[clusters[i]]\n",
    "        for j in range(len(point)):\n",
    "            [k, idx, d] = pcd_tree_max.search_knn_vector_3d(point[j],1)\n",
    "            distance.append(np.sqrt(d)[0])\n",
    "        get_point = point[np.where(distance == np.amin(distance))][0]\n",
    "        tree = cKDTree(point)\n",
    "        point_index = tree.query_ball_point(get_point,0.02)\n",
    "        point_need1 = point[np.where(point[point_index][:,2]>get_point[2])]\n",
    "        point_need2 = point[np.where(point[point_index][:,2]<get_point[2])]\n",
    "        if len(point_need1)==0 or len(point_need2)==0 :\n",
    "            nearest_points_list.append(get_point)\n",
    "            point_list.append(point)\n",
    "    if len(nearest_points_list) > 0 :\n",
    "        pcd_min_point = o3d.geometry.PointCloud()\n",
    "        pcd_min_point.points = o3d.utility.Vector3dVector(np.asarray(nearest_points_list))\n",
    "        # Select points from the downsampled point cloud for repair\n",
    "        pcd_all = pcd_min_point + pcd_down_sample\n",
    "        graph = make_graph(pcd_all,0.3)\n",
    "        points_path_all = []\n",
    "        for i in range(len(nearest_points_list)):\n",
    "            path = get_path_points(np.asarray(nearest_points_list)[i],min_pts,graph)\n",
    "            point_middle = np.mean(point_list[i],axis=0)\n",
    "            middle_dist = np.linalg.norm(np.array(point_middle)-np.array(path[1]))\n",
    "            middle_dist1 = np.linalg.norm(np.array(point_middle)-np.array(path[2]))\n",
    "            if middle_dist1 > middle_dist:\n",
    "                points_remain = remove_points_not_need(np.asarray(pcd.points),np.asarray(point_list[i]))\n",
    "                pcd_remove_points = o3d.geometry.PointCloud()\n",
    "                pcd_remove_points.points = o3d.utility.Vector3dVector(np.asarray(points_remain))\n",
    "                pcd_tree_remove = o3d.geometry.KDTreeFlann(pcd_remove_points)\n",
    "                points_path = []\n",
    "                for l in range(len(path)):\n",
    "                    [k, idx, d] = pcd_tree_remove.search_knn_vector_3d(path[l],1)\n",
    "                    nearest_point =  np.asarray(pcd_remove_points.points)[idx][0]\n",
    "                    [k1, idx1, d1] = pcd_tree_max.search_knn_vector_3d(path[l],1)\n",
    "                    [k2, idx2, d2] = pcd_tree_max.search_knn_vector_3d(nearest_point,1)\n",
    "                    nearest_dist = np.sqrt(d1) - np.sqrt(d2)\n",
    "                    if (np.sqrt(d) > 0.05)  &(path[l][2]>0.45):\n",
    "                        points_path.append(path[l])\n",
    "                    elif (np.sqrt(d) < 0.05) & (path[l][2] > nearest_point[2]) & (nearest_dist > 0) :\n",
    "                        points_path.append(path[l])\n",
    "                    else:\n",
    "                        break\n",
    "                if len(points_path)>0:\n",
    "                    points_path_all.append(points_path)\n",
    "            else:\n",
    "                continue\n",
    "        if len(points_path_all)>0:\n",
    "            # Smooth the selected point cloud\n",
    "            points_smooth = []\n",
    "            for i in range(len(points_path_all)):\n",
    "                points_smooth1 = []\n",
    "                for j in range(len(points_path_all[i])):\n",
    "                    if len(points_path_all[i]) > 2:\n",
    "                            if j ==1:\n",
    "                                p = smooth_skeleton(np.array(points_path_all[i][j-1]),np.array(points_path_all[i][j+1]),np.array(points_path_all[i][j]),10)\n",
    "                                points_smooth.append(p)\n",
    "                                points_smooth1.append(p)\n",
    "                            elif j == len(points_path_all[i])-1:\n",
    "                                break\n",
    "                            elif j > 1:\n",
    "                                p = smooth_skeleton(np.array(points_path_all[i][j-1]),np.array(points_path_all[i][j+1]),p,10)\n",
    "                                points_smooth.append(p)\n",
    "            if len(points_smooth)>0:\n",
    "                pcd_smooth = o3d.geometry.PointCloud()\n",
    "                pcd_smooth.points = o3d.utility.Vector3dVector(np.asarray(points_smooth))\n",
    "                #Add the smoothed point cloud to the skeleton point cloud\n",
    "                pcd_whole = pcd_smooth + pcd\n",
    "            else:\n",
    "                pcd_whole = pcd\n",
    "        else:\n",
    "            pcd_whole = pcd\n",
    "    else:\n",
    "        pcd_whole = pcd\n",
    "    return pcd_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a74f3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_tree_dijkstra(pcd_whole):\n",
    "    points_all = []\n",
    "    graph = make_graph(pcd_whole,0.3)\n",
    "    z_points = sorted(np.asarray(pcd_whole.points), key=(lambda z: z[2]))\n",
    "    min_pts = z_points[0]\n",
    "    outside_points = find_outside_points(np.asarray(pcd_whole.points),0.03,graph)\n",
    "    points_insert = []\n",
    "     # Use linear interpolation to complete\n",
    "    for i in range(len(np.asarray(outside_points))):\n",
    "        path = get_path_points(np.asarray(min_pts),np.asarray(outside_points)[i],graph)\n",
    "        step = 0.005\n",
    "        for j in range(len(path)):\n",
    "             if j != 0:\n",
    "                dist = np.linalg.norm(np.array(path[j])-np.array(path[j-1]))\n",
    "                # If the distance is greater than 0.015, then perform interpolation\n",
    "                if dist >= 0.015:\n",
    "                    number = np.floor(dist/step)\n",
    "                    for k in range(int(number)):\n",
    "                        point_need = np.asarray(path[j-1]) + k * step * (np.asarray(path[j])-np.asarray(path[j-1]))/dist\n",
    "                        points_insert.append(point_need)\n",
    "        points_all.append(points_insert)\n",
    "        points_all.append(path)\n",
    "    concatenated = concatenate_points(points_all)\n",
    "    points_concatenate_remove = np.unique(concatenated,axis=0)\n",
    "     # Obtain the completed point cloud\n",
    "    pcd_finall_repair = o3d.geometry.PointCloud()\n",
    "    pcd_finall_repair.points = o3d.utility.Vector3dVector(np.asarray(points_concatenate_remove))\n",
    "    return pcd_finall_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87858d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
